{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "First we will import all the newly developed modules from the hupml library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hupml imports\n",
    "from hupml import LoadConfig\n",
    "from hupml import MlDataFrame\n",
    "from hupml import PipelineBase\n",
    "\n",
    "# Some imports for this demo\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one module that has been developed that we won't be using today. It's a database connection class. So if you ever work for a client with a database, you can easily kickstart your project by using this. It includes several methods to read and write to the database from/to Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from hupml.database_connection import DbConnection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a couple of other variables and methods for this demo specific:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = (os.path.abspath(os.path.dirname('../..')))\n",
    "\n",
    "def print_dict_pretty(d):\n",
    "    print(json.dumps(d, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading configuration files\n",
    "All configuration files in hupml and ai-template are `.yaml` files. To load these, there is a class in hupml called LoadConfig. This class contains two methods:\n",
    "1. `load_yaml_as_dict`\n",
    "2. `load_logger_from_config`\n",
    "\n",
    "The first method reads the `.yaml` file and converts it to a Python dictionairy. In this way, you can easily add more configuration settings for whatever you want to configure. You can, for instance, add your model parameters in a yaml file instead of keeping these parameters directly in your code. The second method loads the `.yaml` file and configures a logger. More about that in the next section, but first an example of the first method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"version\": 1,\n",
      "    \"root\": {\n",
      "        \"level\": \"NOTSET\",\n",
      "        \"handlers\": [\n",
      "            \"console_handler\"\n",
      "        ]\n",
      "    },\n",
      "    \"disable_existing_loggers\": false,\n",
      "    \"loggers\": {\n",
      "        \"dev\": {\n",
      "            \"level\": \"DEBUG\",\n",
      "            \"handlers\": [\n",
      "                \"file_handler\"\n",
      "            ],\n",
      "            \"propagate\": true\n",
      "        },\n",
      "        \"prod\": {\n",
      "            \"level\": \"INFO\",\n",
      "            \"handlers\": [\n",
      "                \"file_handler\"\n",
      "            ],\n",
      "            \"propagate\": false\n",
      "        }\n",
      "    },\n",
      "    \"handlers\": {\n",
      "        \"console_handler\": {\n",
      "            \"class\": \"logging.StreamHandler\",\n",
      "            \"level\": \"NOTSET\",\n",
      "            \"formatter\": \"standard\",\n",
      "            \"stream\": \"ext://sys.stdout\"\n",
      "        },\n",
      "        \"file_handler\": {\n",
      "            \"class\": \"logging.handlers.RotatingFileHandler\",\n",
      "            \"level\": \"NOTSET\",\n",
      "            \"formatter\": \"standard\",\n",
      "            \"filename\": \"logs/standard.log\",\n",
      "            \"maxBytes\": 10485760,\n",
      "            \"backupCount\": 20,\n",
      "            \"encoding\": \"utf8\"\n",
      "        }\n",
      "    },\n",
      "    \"formatters\": {\n",
      "        \"standard\": {\n",
      "            \"format\": \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Path to config file\n",
    "config_path_logging = f'{root_dir}/configs/logging_settings.yaml'\n",
    "\n",
    "# Load the config from the .yaml file to a Python dictionairy\n",
    "logging_config_dict = LoadConfig.load_yaml_as_dict(config_path_logging)\n",
    "\n",
    "# Print dictionairy in a nice way\n",
    "print_dict_pretty(logging_config_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the previous code block loaded the configuration setting for loggers in dictionairy format. You can easily acces this dictionairy using the key-value pairs. For instance `logging_config_dict['version']` gives `1` and `logging_config_dict['loggers']['dev']['level']` gives `DEBUG`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loggers: Stop using the print method!\n",
    "The `load_logger_from_config` automatically converts the `.yaml` configuration file to a logger ready to use, so you don't have to do this conversion everytime yourself. In the next code block there is an example again.\n",
    "\n",
    "### Why you need loggers\n",
    "Why do I need to use a logger to print stuff on my screen I hear you ask. Python has the `print` method right? Well, using a logger has a lot of advantages. I want to highlight three of them:\n",
    "1. You can configure to see a timestamp.\n",
    "2. You save what you ran automatically in log files. If you log your settings and output of models correctly, you can exactly retrace what your model input and output was at a certain point in time. You can essentially see it as a very basic, automatically generated labjournal.\n",
    "3. There are 4 default logger levels (DEBUG, INFO, WARNING, ERROR) to divide your messages into. It then becomes clearer what _kind_ of message you're logging. Different loggers can output different kind of levels of messages. This can be very useful within different environments. For instance: If you are developing, you usually want to output DEBUG level and higher messages. However, if you want to hand over a model/software product to the client (running in production), you only want to show INFO messages and higher. You can even define your own logging levels in addition to the default ones, if you want. \n",
    "\n",
    "### Using the default loggers\n",
    "You don't need to understand what is in de logger configuration settings to be able to use it. By default, there are two loggers available in the settings: a `dev` logger and a `prod` logger. The `dev` logger outputs DEBUG level and higher messages, the `prod` logger outputs INFO level and higher messages. Both these loggers save their output to `logs/standard.log`. Moreover, the `prod` logger doesn't even output messages on screen, but does this _only in the log file_.\n",
    "\n",
    "Lastly, in the next code block we have to pass the `overwrite_file_name_path` argument. As a little challenge, can you figure out why we need to do this? Hint: look at the `logging_config_dict` in the previous code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-22 12:11:40,585 - dev - DEBUG - debug\n",
      "2020-01-22 12:11:40,585 - dev - INFO - info\n",
      "2020-01-22 12:11:40,589 - dev - WARNING - warning\n",
      "2020-01-22 12:11:40,589 - dev - ERROR - error\n"
     ]
    }
   ],
   "source": [
    "logger_dev = LoadConfig.load_logger_from_config(path=config_path_logging, logger_name='dev', \n",
    "                                                overwrite_file_name_path=f'{root_dir}/logs/standard.log')\n",
    "logger_dev.debug('debug')\n",
    "logger_dev.info('info')\n",
    "logger_dev.warning('warning')\n",
    "logger_dev.error('error')\n",
    "\n",
    "logger_prod = LoadConfig.load_logger_from_config(path=config_path_logging, logger_name='prod', \n",
    "                                                 overwrite_file_name_path=f'{root_dir}/logs/standard.log')\n",
    "logger_prod.debug('debug')\n",
    "logger_prod.info('info')\n",
    "logger_prod.warning('warning')\n",
    "logger_prod.error('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you ran the previous code block, you can checkout the logs folder. Open the `standard.log` file to read back the logger output.\n",
    "\n",
    "For those who _really, really_ want to stick with the `print` method, you can actually overwrite this and _still_ use loggers (not recommended):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-22 12:11:41,203 - dev - INFO - Some message. Can you see a timestamp?\n"
     ]
    }
   ],
   "source": [
    "def print(message):\n",
    "    logger_dev.info(message)\n",
    "\n",
    "print('Some message. Can you see a timestamp?')\n",
    "\n",
    "# Reset for the rest of this document\n",
    "def print(message):\n",
    "    __builtin__.print(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
